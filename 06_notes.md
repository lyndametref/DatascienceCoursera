#Statistical inference
notes from the course Statistical Inference on Coursera

##Definition
Statistical Inference = from sample *guess* the properties of the population

##Kolmogorovâ€™s Three Rules

Consider an experiment with a random outcome. Probability takes a possible outcome from an experiment and:
 0. assigns it a number between 0 and 1
 0. requires that the probability that something occurs is 1 required
 0. required that the probability of the union of any two sets of outcomes that have nothing in common (mutually exclusive)

##Derivative from the thress rules
From the Kolmogorov axioms, one can deduce other useful rules for calculating probabilities.
 0. The probability that nothing occurs is 0
 0. The probability that something occurs is 1 
 0. The probability of something is 1 minus the probability that the opposite occurs
 0. The probability of at least one of two (or more) things that can not simultaneously occur (mutually exclusive) is the sum of their respective probabilities 
 0. For any two events the probability that at least one occurs is the sum of their probabilities minus their intersection.
    
##Probability mass function
*a probability mass function (PMF) is a function that gives the probability that a discrete random variable is exactly equal to some value.*

http://en.wikipedia.org/wiki/Probability_mass_function
